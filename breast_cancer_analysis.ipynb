{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM88ToD/AqZECBYPovAbZNx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimiana17/Doctor-App/blob/main/breast_cancer_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuMtKLxY4DJJ",
        "outputId": "87ca7719-0ca9-46ac-eb37-f9bf34e0b8c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dataprep\n",
            "  Downloading dataprep-0.4.5-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0,>=3.6 in /usr/local/lib/python3.10/dist-packages (from dataprep) (3.9.1)\n",
            "Collecting bokeh<3,>=2 (from dataprep)\n",
            "  Downloading bokeh-2.4.3-py3-none-any.whl (18.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.5/18.5 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dask[array,dataframe,delayed]>=2022.3.0 in /usr/local/lib/python3.10/dist-packages (from dataprep) (2023.8.1)\n",
            "Requirement already satisfied: flask<3,>=2 in /usr/local/lib/python3.10/dist-packages (from dataprep) (2.2.5)\n",
            "Collecting flask_cors<4.0.0,>=3.0.10 (from dataprep)\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: ipywidgets<8.0,>=7.5 in /usr/local/lib/python3.10/dist-packages (from dataprep) (7.7.1)\n",
            "Collecting jinja2<3.1,>=3.0 (from dataprep)\n",
            "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.6/133.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpath-ng<2.0,>=1.5 (from dataprep)\n",
            "  Downloading jsonpath_ng-1.6.0-py3-none-any.whl (29 kB)\n",
            "Collecting metaphone<0.7,>=0.6 (from dataprep)\n",
            "  Downloading Metaphone-0.6.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.7 in /usr/local/lib/python3.10/dist-packages (from dataprep) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.21 in /usr/local/lib/python3.10/dist-packages (from dataprep) (1.23.5)\n",
            "Requirement already satisfied: pandas<2.0,>=1.1 in /usr/local/lib/python3.10/dist-packages (from dataprep) (1.5.3)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.6 in /usr/local/lib/python3.10/dist-packages (from dataprep) (1.10.13)\n",
            "Requirement already satisfied: pydot<2.0.0,>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from dataprep) (1.4.2)\n",
            "Collecting python-crfsuite==0.9.8 (from dataprep)\n",
            "  Downloading python_crfsuite-0.9.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-stdnum<2.0,>=1.16 (from dataprep)\n",
            "  Downloading python_stdnum-1.19-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.1.2 (from dataprep)\n",
            "  Downloading rapidfuzz-2.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex<2022.0.0,>=2021.8.3 (from dataprep)\n",
            "  Downloading regex-2021.11.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.0/764.0 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from dataprep) (1.11.4)\n",
            "Collecting sqlalchemy==1.3.24 (from dataprep)\n",
            "  Downloading SQLAlchemy-1.3.24.tar.gz (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm<5.0,>=4.48 in /usr/local/lib/python3.10/dist-packages (from dataprep) (4.66.1)\n",
            "Collecting varname<0.9.0,>=0.8.1 (from dataprep)\n",
            "  Downloading varname-0.8.3-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: wordcloud<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from dataprep) (1.9.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.6->dataprep) (4.0.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (23.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (6.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from bokeh<3,>=2->dataprep) (4.5.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe,delayed]>=2022.3.0->dataprep) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe,delayed]>=2022.3.0->dataprep) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe,delayed]>=2022.3.0->dataprep) (2023.6.0)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe,delayed]>=2022.3.0->dataprep) (1.4.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe,delayed]>=2022.3.0->dataprep) (0.12.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe,delayed]>=2022.3.0->dataprep) (7.0.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask<3,>=2->dataprep) (3.0.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask<3,>=2->dataprep) (2.1.2)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.10/dist-packages (from flask_cors<4.0.0,>=3.0.10->dataprep) (1.16.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (3.6.6)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<8.0,>=7.5->dataprep) (3.0.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.1,>=3.0->dataprep) (2.1.3)\n",
            "Collecting ply (from jsonpath-ng<2.0,>=1.5->dataprep)\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.7->dataprep) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.1->dataprep) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.1->dataprep) (2023.3.post1)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot<2.0.0,>=1.4.2->dataprep) (3.1.1)\n",
            "Collecting asttokens<3.0.0,>=2.0.0 (from varname<0.9.0,>=0.8.1->dataprep)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting executing<0.9.0,>=0.8.3 (from varname<0.9.0,>=0.8.1->dataprep)\n",
            "  Downloading executing-0.8.3-py2.py3-none-any.whl (16 kB)\n",
            "Collecting pure_eval<1.0.0 (from varname<0.9.0,>=0.8.1->dataprep)\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from wordcloud<2.0,>=1.8->dataprep) (3.7.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (3.17.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<8.0,>=7.5->dataprep) (6.1.12)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (4.9.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.2.0->dask[array,dataframe,delayed]>=2022.3.0->dataprep) (1.0.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (6.5.5)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<4.0,>=3.6->dataprep) (3.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->dataprep) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->dataprep) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->dataprep) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud<2.0,>=1.8->dataprep) (1.4.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.8.3)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (5.5.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.5.8)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.19.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<8.0,>=7.5->dataprep) (0.2.12)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (4.1.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.9.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (2.19.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (4.19.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (21.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.13.2)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (0.5.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8.0,>=7.5->dataprep) (2.21)\n",
            "Building wheels for collected packages: sqlalchemy, metaphone\n",
            "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.3.24-cp310-cp310-linux_x86_64.whl size=1252701 sha256=5284026e8f42e78c0b597741b58be9a4640fd94ca3e38b33e63620e40971402e\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/51/b3/3481e88d5a5ba95dd4aafedc9316774d941c4ba61cfb93add8\n",
            "  Building wheel for metaphone (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for metaphone: filename=Metaphone-0.6-py3-none-any.whl size=13902 sha256=e6c46a4e35759baa490666c3b9bed3ed7f169b496395d945383a695a9e531534\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/dd/1d/6cdd346605db62bde1f60954155e9ce48f4681c243f265b704\n",
            "Successfully built sqlalchemy metaphone\n",
            "Installing collected packages: regex, python-stdnum, python-crfsuite, pure_eval, ply, metaphone, executing, sqlalchemy, rapidfuzz, jsonpath-ng, jinja2, jedi, asttokens, varname, bokeh, flask_cors, dataprep\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2023.6.3\n",
            "    Uninstalling regex-2023.6.3:\n",
            "      Successfully uninstalled regex-2023.6.3\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.23\n",
            "    Uninstalling SQLAlchemy-2.0.23:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.23\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.2\n",
            "    Uninstalling Jinja2-3.1.2:\n",
            "      Successfully uninstalled Jinja2-3.1.2\n",
            "  Attempting uninstall: bokeh\n",
            "    Found existing installation: bokeh 3.3.2\n",
            "    Uninstalling bokeh-3.3.2:\n",
            "      Successfully uninstalled bokeh-3.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "bigframes 0.16.0 requires sqlalchemy<3.0dev,>=1.4, but you have sqlalchemy 1.3.24 which is incompatible.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.3.24 which is incompatible.\n",
            "panel 1.3.4 requires bokeh<3.4.0,>=3.2.0, but you have bokeh 2.4.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asttokens-2.4.1 bokeh-2.4.3 dataprep-0.4.5 executing-0.8.3 flask_cors-3.0.10 jedi-0.19.1 jinja2-3.0.3 jsonpath-ng-1.6.0 metaphone-0.6 ply-3.11 pure_eval-0.2.2 python-crfsuite-0.9.8 python-stdnum-1.19 rapidfuzz-2.15.2 regex-2021.11.10 sqlalchemy-1.3.24 varname-0.8.3\n"
          ]
        }
      ],
      "source": [
        "pip install -U dataprep"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "pDU8Wt4c4yIZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('breast_cancer2.csv')"
      ],
      "metadata": {
        "id": "39EH84pz8A7I"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR0wddDA8HwJ",
        "outputId": "ffdd8555-d136-4ffa-fd71-50ca79aa1d04"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
            "0         M        17.99         10.38          122.80     1001.0   \n",
            "1         M        20.57         17.77          132.90     1326.0   \n",
            "2         M        19.69         21.25          130.00     1203.0   \n",
            "3         M        11.42         20.38           77.58      386.1   \n",
            "4         M        20.29         14.34          135.10     1297.0   \n",
            "\n",
            "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
            "0          0.11840           0.27760          0.3001              0.14710   \n",
            "1          0.08474           0.07864          0.0869              0.07017   \n",
            "2          0.10960           0.15990          0.1974              0.12790   \n",
            "3          0.14250           0.28390          0.2414              0.10520   \n",
            "4          0.10030           0.13280          0.1980              0.10430   \n",
            "\n",
            "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
            "0         0.2419  ...         25.38          17.33           184.60   \n",
            "1         0.1812  ...         24.99          23.41           158.80   \n",
            "2         0.2069  ...         23.57          25.53           152.50   \n",
            "3         0.2597  ...         14.91          26.50            98.87   \n",
            "4         0.1809  ...         22.54          16.67           152.20   \n",
            "\n",
            "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
            "0      2019.0            0.1622             0.6656           0.7119   \n",
            "1      1956.0            0.1238             0.1866           0.2416   \n",
            "2      1709.0            0.1444             0.4245           0.4504   \n",
            "3       567.7            0.2098             0.8663           0.6869   \n",
            "4      1575.0            0.1374             0.2050           0.4000   \n",
            "\n",
            "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
            "0                0.2654          0.4601                  0.11890  \n",
            "1                0.1860          0.2750                  0.08902  \n",
            "2                0.2430          0.3613                  0.08758  \n",
            "3                0.2575          0.6638                  0.12301  \n",
            "4                0.1625          0.2364                  0.07678  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "gWekHMZn8MBV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('diagnosis', axis=1)  # Features\n",
        "y = df['diagnosis']  # Target variable\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ugOi0gQr8P1o"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "XW3zcBl482Qx",
        "outputId": "5adb913b-39e2-44b9-882e-24902596696c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Confusion Matrix:\\n{confusion_mat}')\n",
        "print(f'Classification Report:\\n{classification_rep}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZqT-sF986_n",
        "outputId": "db5fdf48-170d-41c1-917e-f1d098b83bcc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9385964912280702\n",
            "Confusion Matrix:\n",
            "[[68  3]\n",
            " [ 4 39]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.94      0.96      0.95        71\n",
            "           M       0.93      0.91      0.92        43\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.94      0.93      0.93       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load your dataset\n",
        "# Replace 'your_dataset.csv' with your actual file name or path\n",
        "df = pd.read_csv('breast_cancer2.csv')\n",
        "\n",
        "# Preprocess Your Data\n",
        "# Handle missing values if necessary\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical variables if necessary\n",
        "# Example: df = pd.get_dummies(df, columns=['categorical_column'])\n",
        "\n",
        "# Split the Data into Training and Testing Sets\n",
        "X = df.drop('diagnosis', axis=1)  # Features\n",
        "y = df['diagnosis']  # Target variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and Train the Decision Tree Model\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions on the Training Set\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on the Training Set\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "train_confusion_mat = confusion_matrix(y_train, y_train_pred)\n",
        "train_classification_rep = classification_report(y_train, y_train_pred)\n",
        "\n",
        "# Make Predictions on the Testing Set\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the Testing Set\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_confusion_mat = confusion_matrix(y_test, y_test_pred)\n",
        "test_classification_rep = classification_report(y_test, y_test_pred)\n",
        "\n",
        "# Display Results\n",
        "print(\"Training Results:\")\n",
        "print(f'Training Accuracy: {train_accuracy}')\n",
        "print(f'Training Confusion Matrix:\\n{train_confusion_mat}')\n",
        "print(f'Training Classification Report:\\n{train_classification_rep}')\n",
        "\n",
        "print(\"\\nTesting Results:\")\n",
        "print(f'Testing Accuracy: {test_accuracy}')\n",
        "print(f'Testing Confusion Matrix:\\n{test_confusion_mat}')\n",
        "print(f'Testing Classification Report:\\n{test_classification_rep}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drzRzaYZ_Eyp",
        "outputId": "5c049b6c-86c3-419f-def8-40a73b39bd97"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results:\n",
            "Training Accuracy: 1.0\n",
            "Training Confusion Matrix:\n",
            "[[286   0]\n",
            " [  0 169]]\n",
            "Training Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       1.00      1.00      1.00       286\n",
            "           M       1.00      1.00      1.00       169\n",
            "\n",
            "    accuracy                           1.00       455\n",
            "   macro avg       1.00      1.00      1.00       455\n",
            "weighted avg       1.00      1.00      1.00       455\n",
            "\n",
            "\n",
            "Testing Results:\n",
            "Testing Accuracy: 0.9385964912280702\n",
            "Testing Confusion Matrix:\n",
            "[[68  3]\n",
            " [ 4 39]]\n",
            "Testing Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.94      0.96      0.95        71\n",
            "           M       0.93      0.91      0.92        43\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.94      0.93      0.93       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load your dataset\n",
        "# Replace 'your_dataset.csv' with your actual file name or path\n",
        "df = pd.read_csv('breast_cancer2.csv')\n",
        "\n",
        "# Preprocess Your Data\n",
        "# Handle missing values if necessary\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical variables if necessary\n",
        "# Example: df = pd.get_dummies(df, columns=['categorical_column'])\n",
        "\n",
        "# Split the Data into Training and Testing Sets\n",
        "X = df.drop('diagnosis', axis=1)  # Features\n",
        "y = df['diagnosis']  # Target variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and Train the Random Forest Model\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions on the Training Set\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on the Training Set\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "train_confusion_mat = confusion_matrix(y_train, y_train_pred)\n",
        "train_classification_rep = classification_report(y_train, y_train_pred)\n",
        "\n",
        "# Make Predictions on the Testing Set\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the Testing Set\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_confusion_mat = confusion_matrix(y_test, y_test_pred)\n",
        "test_classification_rep = classification_report(y_test, y_test_pred)\n",
        "\n",
        "# Display Results\n",
        "print(\"Training Results:\")\n",
        "print(f'Training Accuracy: {train_accuracy}')\n",
        "print(f'Training Confusion Matrix:\\n{train_confusion_mat}')\n",
        "print(f'Training Classification Report:\\n{train_classification_rep}')\n",
        "\n",
        "print(\"\\nTesting Results:\")\n",
        "print(f'Testing Accuracy: {test_accuracy}')\n",
        "print(f'Testing Confusion Matrix:\\n{test_confusion_mat}')\n",
        "print(f'Testing Classification Report:\\n{test_classification_rep}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPmw3XdMAXYH",
        "outputId": "2782e9ff-7b19-4669-abe6-1b833ee85921"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results:\n",
            "Training Accuracy: 1.0\n",
            "Training Confusion Matrix:\n",
            "[[286   0]\n",
            " [  0 169]]\n",
            "Training Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       1.00      1.00      1.00       286\n",
            "           M       1.00      1.00      1.00       169\n",
            "\n",
            "    accuracy                           1.00       455\n",
            "   macro avg       1.00      1.00      1.00       455\n",
            "weighted avg       1.00      1.00      1.00       455\n",
            "\n",
            "\n",
            "Testing Results:\n",
            "Testing Accuracy: 0.956140350877193\n",
            "Testing Confusion Matrix:\n",
            "[[69  2]\n",
            " [ 3 40]]\n",
            "Testing Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.96      0.97      0.97        71\n",
            "           M       0.95      0.93      0.94        43\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load your dataset\n",
        "# Replace 'your_dataset.csv' with your actual file name or path\n",
        "df = pd.read_csv('breast_cancer2.csv')\n",
        "\n",
        "# Preprocess Your Data\n",
        "# Handle missing values if necessary\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical variables if necessary\n",
        "# Example: df = pd.get_dummies(df, columns=['categorical_column'])\n",
        "\n",
        "# Split the Data into Training and Testing Sets\n",
        "X = df.drop('diagnosis', axis=1)  # Features\n",
        "y = df['diagnosis']  # Target variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and Train the Support Vector Machine Model\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions on the Training Set\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on the Training Set\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "train_confusion_mat = confusion_matrix(y_train, y_train_pred)\n",
        "train_classification_rep = classification_report(y_train, y_train_pred)\n",
        "\n",
        "# Make Predictions on the Testing Set\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the Testing Set\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_confusion_mat = confusion_matrix(y_test, y_test_pred)\n",
        "test_classification_rep = classification_report(y_test, y_test_pred)\n",
        "\n",
        "# Display Results\n",
        "print(\"Training Results:\")\n",
        "print(f'Training Accuracy: {train_accuracy}')\n",
        "print(f'Training Confusion Matrix:\\n{train_confusion_mat}')\n",
        "print(f'Training Classification Report:\\n{train_classification_rep}')\n",
        "\n",
        "print(\"\\nTesting Results:\")\n",
        "print(f'Testing Accuracy: {test_accuracy}')\n",
        "print(f'Testing Confusion Matrix:\\n{test_confusion_mat}')\n",
        "print(f'Testing Classification Report:\\n{test_classification_rep}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CKQWvy1BBZQ",
        "outputId": "38da8166-9fb4-4913-879a-92043eae007c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results:\n",
            "Training Accuracy: 0.9142857142857143\n",
            "Training Confusion Matrix:\n",
            "[[281   5]\n",
            " [ 34 135]]\n",
            "Training Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.89      0.98      0.94       286\n",
            "           M       0.96      0.80      0.87       169\n",
            "\n",
            "    accuracy                           0.91       455\n",
            "   macro avg       0.93      0.89      0.90       455\n",
            "weighted avg       0.92      0.91      0.91       455\n",
            "\n",
            "\n",
            "Testing Results:\n",
            "Testing Accuracy: 0.9473684210526315\n",
            "Testing Confusion Matrix:\n",
            "[[71  0]\n",
            " [ 6 37]]\n",
            "Testing Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.92      1.00      0.96        71\n",
            "           M       1.00      0.86      0.92        43\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.96      0.93      0.94       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load your dataset\n",
        "# Replace 'your_dataset.csv' with your actual file name or path\n",
        "df = pd.read_csv('breast_cancer2.csv')\n",
        "\n",
        "# Preprocess Your Data\n",
        "# Handle missing values if necessary\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical variables if necessary\n",
        "# Example: df = pd.get_dummies(df, columns=['categorical_column'])\n",
        "\n",
        "# Split the Data into Training and Testing Sets\n",
        "X = df.drop('diagnosis', axis=1)  # Features\n",
        "y = df['diagnosis']  # Target variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and Train the k-Nearest Neighbors Model\n",
        "k = 3  # You can adjust the number of neighbors (k) based on your needs\n",
        "model = KNeighborsClassifier(n_neighbors=k)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions on the Training Set\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on the Training Set\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "train_confusion_mat = confusion_matrix(y_train, y_train_pred)\n",
        "train_classification_rep = classification_report(y_train, y_train_pred)\n",
        "\n",
        "# Make Predictions on the Testing Set\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the Testing Set\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_confusion_mat = confusion_matrix(y_test, y_test_pred)\n",
        "test_classification_rep = classification_report(y_test, y_test_pred)\n",
        "\n",
        "# Display Results\n",
        "print(\"Training Results:\")\n",
        "print(f'Training Accuracy: {train_accuracy}')\n",
        "print(f'Training Confusion Matrix:\\n{train_confusion_mat}')\n",
        "print(f'Training Classification Report:\\n{train_classification_rep}')\n",
        "\n",
        "print(\"\\nTesting Results:\")\n",
        "print(f'Testing Accuracy: {test_accuracy}')\n",
        "print(f'Testing Confusion Matrix:\\n{test_confusion_mat}')\n",
        "print(f'Testing Classification Report:\\n{test_classification_rep}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo5G1YHeB3zG",
        "outputId": "7e38e956-96b5-49fb-97f2-f2fd2f165d0e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results:\n",
            "Training Accuracy: 0.9494505494505494\n",
            "Training Confusion Matrix:\n",
            "[[281   5]\n",
            " [ 18 151]]\n",
            "Training Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.94      0.98      0.96       286\n",
            "           M       0.97      0.89      0.93       169\n",
            "\n",
            "    accuracy                           0.95       455\n",
            "   macro avg       0.95      0.94      0.94       455\n",
            "weighted avg       0.95      0.95      0.95       455\n",
            "\n",
            "\n",
            "Testing Results:\n",
            "Testing Accuracy: 0.9298245614035088\n",
            "Testing Confusion Matrix:\n",
            "[[68  3]\n",
            " [ 5 38]]\n",
            "Testing Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.93      0.96      0.94        71\n",
            "           M       0.93      0.88      0.90        43\n",
            "\n",
            "    accuracy                           0.93       114\n",
            "   macro avg       0.93      0.92      0.92       114\n",
            "weighted avg       0.93      0.93      0.93       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load your dataset\n",
        "# Replace 'your_dataset.csv' with your actual file name or path\n",
        "df = pd.read_csv('breast_cancer2.csv')\n",
        "\n",
        "# Preprocess Your Data\n",
        "# Handle missing values if necessary\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical variables if necessary\n",
        "# Example: df = pd.get_dummies(df, columns=['categorical_column'])\n",
        "\n",
        "# Split the Data into Training and Testing Sets\n",
        "X = df.drop('diagnosis', axis=1)  # Features\n",
        "y = df['diagnosis']  # Target variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and Train the Decision Tree Model\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions on the Testing Set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Display Results\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Confusion Matrix:\\n{confusion_mat}')\n",
        "print(f'Classification Report:\\n{classification_rep}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWH5KGsYEP4g",
        "outputId": "7bcbf83d-63a8-44bb-d818-07bcf45ba3ea"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9385964912280702\n",
            "Confusion Matrix:\n",
            "[[67  4]\n",
            " [ 3 40]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.96      0.94      0.95        71\n",
            "           M       0.91      0.93      0.92        43\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.93      0.94      0.93       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load your dataset\n",
        "# Replace 'your_dataset.csv' with your actual file name or path\n",
        "df = pd.read_csv('breast_cancer2.csv')\n",
        "\n",
        "# Preprocess Your Data\n",
        "# Handle missing values if necessary\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical variables if necessary\n",
        "# Example: df = pd.get_dummies(df, columns=['categorical_column'])\n",
        "\n",
        "# Split the Data into Training and Testing Sets\n",
        "X = df.drop('diagnosis', axis=1)  # Features\n",
        "y = df['diagnosis']  # Target variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and Train the Neural Network Model\n",
        "model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions on the Training Set\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on the Training Set\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "train_confusion_mat = confusion_matrix(y_train, y_train_pred)\n",
        "train_classification_rep = classification_report(y_train, y_train_pred)\n",
        "\n",
        "# Make Predictions on the Testing Set\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the Testing Set\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_confusion_mat = confusion_matrix(y_test, y_test_pred)\n",
        "test_classification_rep = classification_report(y_test, y_test_pred)\n",
        "\n",
        "# Display Results\n",
        "print(\"Training Results:\")\n",
        "print(f'Training Accuracy: {train_accuracy}')\n",
        "print(f'Training Confusion Matrix:\\n{train_confusion_mat}')\n",
        "print(f'Training Classification Report:\\n{train_classification_rep}')\n",
        "\n",
        "print(\"\\nTesting Results:\")\n",
        "print(f'Testing Accuracy: {test_accuracy}')\n",
        "print(f'Testing Confusion Matrix:\\n{test_confusion_mat}')\n",
        "print(f'Testing Classification Report:\\n{test_classification_rep}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyVY8GOeGiYd",
        "outputId": "46510948-9653-4e67-e845-09865053dbe7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results:\n",
            "Training Accuracy: 0.9252747252747253\n",
            "Training Confusion Matrix:\n",
            "[[284   2]\n",
            " [ 32 137]]\n",
            "Training Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.90      0.99      0.94       286\n",
            "           M       0.99      0.81      0.89       169\n",
            "\n",
            "    accuracy                           0.93       455\n",
            "   macro avg       0.94      0.90      0.92       455\n",
            "weighted avg       0.93      0.93      0.92       455\n",
            "\n",
            "\n",
            "Testing Results:\n",
            "Testing Accuracy: 0.9385964912280702\n",
            "Testing Confusion Matrix:\n",
            "[[71  0]\n",
            " [ 7 36]]\n",
            "Testing Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.91      1.00      0.95        71\n",
            "           M       1.00      0.84      0.91        43\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.96      0.92      0.93       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load your dataset\n",
        "# Replace 'your_dataset.csv' with your actual file name or path\n",
        "df = pd.read_csv('breast_cancer2.csv')\n",
        "\n",
        "# Preprocess Your Data\n",
        "# Handle missing values if necessary\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical variables if necessary\n",
        "# Example: df = pd.get_dummies(df, columns=['categorical_column'])\n",
        "\n",
        "# Split the Data into Training and Testing Sets\n",
        "X = df.drop('diagnosis', axis=1)  # Features\n",
        "y = df['diagnosis']  # Target variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and Train the Support Vector Machine Model\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions on the Training Set\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on the Training Set\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "train_confusion_mat = confusion_matrix(y_train, y_train_pred)\n",
        "train_classification_rep = classification_report(y_train, y_train_pred)\n",
        "\n",
        "# Make Predictions on the Testing Set\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the Testing Set\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_confusion_mat = confusion_matrix(y_test, y_test_pred)\n",
        "test_classification_rep = classification_report(y_test, y_test_pred)\n",
        "\n",
        "# Display Results\n",
        "print(\"Training Results:\")\n",
        "print(f'Training Accuracy: {train_accuracy}')\n",
        "print(f'Training Confusion Matrix:\\n{train_confusion_mat}')\n",
        "print(f'Training Classification Report:\\n{train_classification_rep}')\n",
        "\n",
        "print(\"\\nTesting Results:\")\n",
        "print(f'Testing Accuracy: {test_accuracy}')\n",
        "print(f'Testing Confusion Matrix:\\n{test_confusion_mat}')\n",
        "print(f'Testing Classification Report:\\n{test_classification_rep}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysJ1B9cXHims",
        "outputId": "eb7b255c-abc6-4a02-fa2e-47fee7651bfc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results:\n",
            "Training Accuracy: 0.9142857142857143\n",
            "Training Confusion Matrix:\n",
            "[[281   5]\n",
            " [ 34 135]]\n",
            "Training Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.89      0.98      0.94       286\n",
            "           M       0.96      0.80      0.87       169\n",
            "\n",
            "    accuracy                           0.91       455\n",
            "   macro avg       0.93      0.89      0.90       455\n",
            "weighted avg       0.92      0.91      0.91       455\n",
            "\n",
            "\n",
            "Testing Results:\n",
            "Testing Accuracy: 0.9473684210526315\n",
            "Testing Confusion Matrix:\n",
            "[[71  0]\n",
            " [ 6 37]]\n",
            "Testing Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.92      1.00      0.96        71\n",
            "           M       1.00      0.86      0.92        43\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.96      0.93      0.94       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load your dataset\n",
        "# Replace 'your_dataset.csv' with your actual file name or path\n",
        "df = pd.read_csv('breast_cancer2.csv')\n",
        "\n",
        "# Preprocess Your Data\n",
        "# Handle missing values if necessary\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical variables if necessary\n",
        "# Example: df = pd.get_dummies(df, columns=['categorical_column'])\n",
        "\n",
        "# Split the Data into Training and Testing Sets\n",
        "X = df.drop('diagnosis', axis=1)  # Features\n",
        "y = df['diagnosis']  # Target variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and Train the XGBoost Model\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions on the Training Set\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on the Training Set\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "train_confusion_mat = confusion_matrix(y_train, y_train_pred)\n",
        "train_classification_rep = classification_report(y_train, y_train_pred)\n",
        "\n",
        "# Make Predictions on the Testing Set\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the Testing Set\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_confusion_mat = confusion_matrix(y_test, y_test_pred)\n",
        "test_classification_rep = classification_report(y_test, y_test_pred)\n",
        "\n",
        "# Display Results\n",
        "print(\"Training Results:\")\n",
        "print(f'Training Accuracy: {train_accuracy}')\n",
        "print(f'Training Confusion Matrix:\\n{train_confusion_mat}')\n",
        "print(f'Training Classification Report:\\n{train_classification_rep}')\n",
        "\n",
        "print(\"\\nTesting Results:\")\n",
        "print(f'Testing Accuracy: {test_accuracy}')\n",
        "print(f'Testing Confusion Matrix:\\n{test_confusion_mat}')\n",
        "print(f'Testing Classification Report:\\n{test_classification_rep}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "Yt3bmp5LITGv",
        "outputId": "aa79b772-1d98-4eb6-b922-fee0e967eff9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-bbe9ea66963a>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Build and Train the XGBoost Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Make Predictions on the Training Set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1465\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpected_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m             ):\n\u001b[0;32m-> 1467\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1468\u001b[0m                     \u001b[0;34mf\"Invalid classes inferred from unique values of `y`.  \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m                     \u001b[0;34mf\"Expected: {expected_classes}, got {classes}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got ['B' 'M']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load your dataset\n",
        "# Replace 'your_dataset.csv' with your actual file name or path\n",
        "df = pd.read_csv('breast_cancer2.csv')\n",
        "\n",
        "# Preprocess Your Data\n",
        "# Handle missing values if necessary\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical variables if necessary\n",
        "# Example: df = pd.get_dummies(df, columns=['categorical_column'])\n",
        "\n",
        "# Split the Data into Training and Testing Sets\n",
        "X = df.drop('diagnosis', axis=1)  # Features\n",
        "y = df['diagnosis']  # Target variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and Train the Random Forest Model\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions on the Training Set\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "# Evaluate the model on the Training Set\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "train_confusion_mat = confusion_matrix(y_train, y_train_pred)\n",
        "train_classification_rep = classification_report(y_train, y_train_pred)\n",
        "\n",
        "# Make Predictions on the Testing Set\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the Testing Set\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_confusion_mat = confusion_matrix(y_test, y_test_pred)\n",
        "test_classification_rep = classification_report(y_test, y_test_pred)\n",
        "\n",
        "# Display Results\n",
        "print(\"Training Results:\")\n",
        "print(f'Training Accuracy: {train_accuracy}')\n",
        "print(f'Training Confusion Matrix:\\n{train_confusion_mat}')\n",
        "print(f'Training Classification Report:\\n{train_classification_rep}')\n",
        "\n",
        "print(\"\\nTesting Results:\")\n",
        "print(f'Testing Accuracy: {test_accuracy}')\n",
        "print(f'Testing Confusion Matrix:\\n{test_confusion_mat}')\n",
        "print(f'Testing Classification Report:\\n{test_classification_rep}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIbX00i9JJdc",
        "outputId": "7edf1c51-767c-4589-bae2-ab282b3903d2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results:\n",
            "Training Accuracy: 1.0\n",
            "Training Confusion Matrix:\n",
            "[[286   0]\n",
            " [  0 169]]\n",
            "Training Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       1.00      1.00      1.00       286\n",
            "           M       1.00      1.00      1.00       169\n",
            "\n",
            "    accuracy                           1.00       455\n",
            "   macro avg       1.00      1.00      1.00       455\n",
            "weighted avg       1.00      1.00      1.00       455\n",
            "\n",
            "\n",
            "Testing Results:\n",
            "Testing Accuracy: 0.9649122807017544\n",
            "Testing Confusion Matrix:\n",
            "[[70  1]\n",
            " [ 3 40]]\n",
            "Testing Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.96      0.99      0.97        71\n",
            "           M       0.98      0.93      0.95        43\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    }
  ]
}